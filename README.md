# üìù G√©n√©rateur de Quizz & Exercices IA (Streamlit + LangGraph)

Application Streamlit permettant de g√©n√©rer automatiquement des **Quizz QCM** et des **Exercices math√©matiques/logiques** √† partir de documents PDF, en utilisant des mod√®les LLM via l'API OpenAI (ou compatible).

## ‚ú® Fonctionnalit√©s

### üéØ Quizz QCM
- **Extraction intelligente** du texte depuis un PDF (modes Paragraphe / Global / Hybride).
- **G√©n√©ration personnalisable** :
  - Difficult√© : Facile, Moyen, Difficile.
  - Nombre de questions (3 √† 30).
  - Nombre de choix de r√©ponses (A, B, C, D... jusqu'√† G).
  - Nombre de bonnes r√©ponses (choix multiple possible).
- **Export HTML interactif** : T√©l√©chargez un fichier HTML autonome avec design sombre, score en temps r√©el et explications d√©taill√©es.

### üßÆ Exercices & Probl√®mes (Maths / Logique / Science)
- **G√©n√©ration d'exercices complexes** n√©cessitant calcul et raisonnement.
- **V√©rification automatique par Agent IA** : Un agent LangGraph ex√©cute du code Python pour v√©rifier la validit√© de la r√©ponse et de la correction propos√©e par le LLM.
- **Affichage complet** : √ânonc√©, R√©ponse attendue, √âtapes de r√©solution d√©taill√©es, Code de v√©rification Python.

---

## üõ†Ô∏è Installation

### Pr√©requis
- Python 3.10 ou sup√©rieur.
- [uv](https://github.com/astral-sh/uv) (recommand√© pour la gestion d'environnement, sinon pip/conda).
- Acc√®s √† une API compatible OpenAI (OpenAI, LocalAI, vLLM, etc.).

### 1. Cloner le projet
```bash
git clone <votre-repo>
cd generateur_de_quizz
```

### 2. Cr√©er l'environnement virtuel et installer les d√©pendances

**Avec UV (recommand√©) :**
```bash
uv venv .venv
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate

uv pip install -r requirements.txt
```

**Avec Pip standard :**
```bash
python -m venv .venv
# Activer l'environnement...
pip install -r requirements.txt
```

### 3. Configuration (.env)

Copiez le fichier `.env.example` vers `.env` et configurez vos acc√®s API :

```bash
cp .env.example .env
```

√âditez `.env` :
```ini
# URL de base de votre API (ex: API locale, OpenAI, vLLM...)
OPENAI_API_BASE=http://votre-serveur:8080/v1

# Cl√© API (si n√©cessaire)
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxx

# Nom du mod√®le √† utiliser
MODEL_NAME=gtp-oss-120b

# Fen√™tre de contexte du mod√®le (en tokens)
MODEL_CONTEXT_WINDOW=32000
```

---

## üöÄ Utilisation

Lancez l'application Streamlit :

```bash
streamlit run app.py
```

L'application s'ouvrira dans votre navigateur par d√©faut (g√©n√©ralement `http://localhost:8501`).

1.  **Upload** : Chargez votre fichier PDF dans la barre lat√©rale.
2.  **Configuration** : Ajustez le mode de lecture (recommand√© : "Hybride") et la taille des chunks.
3.  **Onglet Quizz** :
    *   Choisissez la difficult√© et les param√®tres.
    *   Cliquez sur **"G√©n√©rer le Quizz"**.
    *   Visualisez les questions et t√©l√©chargez le fichier HTML.
4.  **Onglet Exercices** :
    *   Choisissez le nombre d'exercices.
    *   Cliquez sur **"G√©n√©rer les Exercices"**.
    *   L'agent IA va g√©n√©rer et *v√©rifier* chaque exercice via l'ex√©cution de code Python.

---

## üèóÔ∏è Architecture du projet

- `app.py` : Interface utilisateur principale (Streamlit).
- `pdf_processor.py` : Extraction de texte (pdfplumber) et d√©coupage intelligent (tiktoken).
- `llm_service.py` : Client API OpenAI, gestion des tokens et retry logic.
- `quiz_generator.py` : Logique de cr√©ation des QCM (prompts, parsing JSON).
- `exercise_generator.py` : Cr√©ation d'exercices et **V√©rification Agentique** (LangGraph + PythonREPLTool).
- `quiz_exporter.py` : Moteur de rendu HTML (Jinja2).
- `templates/quiz_template.html` : Template HTML/CSS/JS pour l'export des quizz.

## üì¶ D√©pendances principales

- `streamlit` : Interface Web.
- `langchain`, `langgraph`, `langchain-openai`, `langchain-experimental` : Orchestration LLM et Agents.
- `openai` : Client API standard.
- `pdfplumber` : Extraction PDF robuste.
- `tiktoken` : Tokenizer OpenAI rapide.
- `jinja2` : Templating HTML.

---

## ‚ö†Ô∏è Notes importantes

- **S√©curit√©** : L'agent de v√©rification des exercices ex√©cute du code Python g√©n√©r√© par le LLM **localement**. Bien que `PythonREPLTool` soit utilis√©, il n'y a pas de sandbox Docker par d√©faut. Utilisez ce logiciel dans un environnement de confiance ou configurez un environnement d'ex√©cution isol√© si n√©cessaire pour la production.
- **Mod√®les** : Test√© avec `gtp-oss-120b` (contexte 32k). Ajustez `MODEL_CONTEXT_WINDOW` dans le `.env` si vous utilisez un mod√®le diff√©rent.
- **Chunking** : Si le PDF est tr√®s long, le mode "Global" peut d√©passer la fen√™tre de contexte. Pr√©f√©rez le mode "Paragraphe" ou "Hybride" avec une taille de chunk raisonnable (2000-4000 tokens).

## üìÑ Licence

Projet personnel / interne.
