# üìù G√©n√©rateur de Quizz & Exercices IA (Streamlit + LangGraph)

Application Streamlit permettant de g√©n√©rer automatiquement des **Quizz QCM** et des **Exercices math√©matiques/logiques** √† partir de documents PDF, DOCX, ODT, PPTX et TXT, en utilisant des mod√®les LLM via l'API OpenAI (ou compatible).

## ‚ú® Fonctionnalit√©s

### üéØ Quizz QCM
- **Extraction multi-format** : Support des fichiers **PDF, DOCX, ODT, ODP, PPTX et TXT**.
- **Extraction flexible** du texte :
  - **Mode "Page par page / Slide par slide"** : Id√©al pour conserver la r√©f√©rence pr√©cise des sources.
  - **Mode "Par blocs de tokens"** : Permet d'analyser de longs contextes en continu (fen√™tre glissante).
- **S√©lection dynamique du mod√®le** : Choisissez le mod√®le LLM directement depuis l'interface (r√©cup√©ration automatique via l'API).
- **G√©n√©ration multi-niveaux** : 
  - Configurez simultan√©ment le nombre de questions pour chaque niveau (**Facile**, **Moyen**, **Difficile**) en un seul run.
  - **√âditeur de Prompts** : Personnalisez totalement les instructions p√©dagogiques pour chaque niveau de difficult√© directement dans l'interface.
- **Param√©trage pr√©cis** :
  - Nombre de choix de r√©ponses (A, B, C, D... jusqu'√† G).
  - Nombre de bonnes r√©ponses (choix multiple possible).
- **Export HTML interactif** : T√©l√©chargez un fichier HTML autonome avec design sombre, score en temps r√©el et explications d√©taill√©es.

### üßÆ Exercices & Probl√®mes (Maths / Logique / Science)
- **G√©n√©ration d'exercices complexes** n√©cessitant calcul et raisonnement.
- **V√©rification automatique par Agent IA** : Un agent LangGraph ex√©cute du code Python pour v√©rifier la validit√© de la r√©ponse et de la correction propos√©e par le LLM.
- **Affichage complet** : √ânonc√©, R√©ponse attendue, √âtapes de r√©solution d√©taill√©es, Code de v√©rification Python.

---

## üõ†Ô∏è Installation

### Pr√©requis
- Python 3.10 ou sup√©rieur.
- [uv](https://github.com/astral-sh/uv) (recommand√© pour la gestion d'environnement, sinon pip/conda).
- Acc√®s √† une API compatible OpenAI (OpenAI, LocalAI, vLLM, etc.).

### 1. Cloner le projet
```bash
git clone <votre-repo>
cd generateur_de_quizz
```

### 2. Cr√©er l'environnement virtuel et installer les d√©pendances

**Avec UV (recommand√©) :**
```bash
uv venv .venv
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate

uv pip install -r requirements.txt
```

**Avec Pip standard :**
```bash
python -m venv .venv
# Activer l'environnement...
pip install -r requirements.txt
```

### 3. Configuration (.env)

Copiez le fichier `.env.example` vers `.env` et configurez vos acc√®s API :

```bash
cp .env.example .env
```

√âditez `.env` :
```ini
# URL de base de votre API (ex: API locale, OpenAI, vLLM...)
OPENAI_API_BASE=http://votre-serveur:8080/v1

# Cl√© API (si n√©cessaire)
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxx

# Nom du mod√®le √† utiliser
MODEL_NAME=gtp-oss-120b

# Fen√™tre de contexte du mod√®le (en tokens)
MODEL_CONTEXT_WINDOW=32000
```

---

## üöÄ Utilisation

Lancez l'application Streamlit :

```bash
streamlit run app.py
```

L'application s'ouvrira dans votre navigateur par d√©faut (g√©n√©ralement `http://localhost:8501`).

1.  **Upload** : Chargez votre fichier (PDF, DOCX, ODT...) dans la barre lat√©rale.
2.  **Configuration** : 
    * Ajustez le mode de lecture (recommand√© : "Hybride") et la taille des chunks.
    * S√©lectionnez le **Mod√®le LLM** souhait√© dans la liste d√©roulante.
3.  **Onglet Quizz** :
    *   Saisissez le nombre de questions pour chaque niveau (Facile, Moyen, Difficile).
    *   (Optionnel) Modifiez les instructions sp√©cifiques envoy√©es √† l'IA dans l'expandeur **"Personnaliser les Prompts"**.
    *   Cliquez sur **"G√©n√©rer le Quizz"**.
    *   Visualisez les questions et t√©l√©chargez le fichier HTML.
4.  **Onglet Exercices** :
    *   Choisissez le nombre d'exercices.
    *   Cliquez sur **"G√©n√©rer les Exercices"**.
    *   L'agent IA va g√©n√©rer et *v√©rifier* chaque exercice via l'ex√©cution de code Python.

## üß† Fonctionnement d√©taill√©

### üìè Strat√©gies de Chunking
Le logiciel d√©coupe le PDF en "chunks" (segments) avant de les envoyer au LLM pour √©viter de d√©passer la fen√™tre de contexte et pour permettre une analyse cibl√©e :
- **Page par page (D√©faut)** : Chaque page est trait√©e comme une unit√© isol√©e. C'est la m√©thode la plus pr√©cise pour l'attribution des sources.
- **Par blocs de tokens** : Le texte est d√©coup√© en segments de taille fixe (ex: 10 000 tokens) avec chevauchement. 
  - Id√©al pour analyser des contextes longs.
  - **Pr√©cision** : Des marqueurs `[D√©but Page X] ... [Fin Page X]` sont ins√©r√©s automatiquement dans le texte pour que l'IA puisse citer pr√©cis√©ment ses sources, m√™me au milieu d'un bloc de 50 pages.

### üéØ Distribution des Questions (Quizz)
Le syst√®me ne se contente pas d'envoyer tout le texte au hasard. Pour un quizz de $N$ questions :
1. Il calcule le poids de chaque chunk par rapport au volume total de texte.
2. Il r√©partit les $N$ questions proportionnellement √† la taille des chunks.
3. Seuls les chunks "utiles" sont envoy√©s √† l'IA, optimisant ainsi la consommation de tokens et la pertinence p√©dagogique.

### ü§ñ V√©rification Agentique (Exercices)
Contrairement aux quizz classiques, les exercices math√©matiques ou logiques passent par un cycle de **v√©rification en boucle ferm√©e** :
1. **G√©n√©ration** : Un premier LLM cr√©e l'√©nonc√©, la solution et un script Python de v√©rification.
2. **Ex√©cution** : Un **Agent ReAct** (via LangGraph) prend le script, l'ex√©cute dans un environnement Python (REPL).
3. **Validation** : L'agent compare le r√©sultat de l'ex√©cution avec la r√©ponse annonc√©e par le premier LLM. 
   - Si les r√©sultats concordent, l'exercice est marqu√© comme **V√©rifi√© ‚úÖ**.
   - En cas d'erreur, le syst√®me peut tenter de re-g√©n√©rer l'exercice (auto-correction).

---

## üèóÔ∏è Architecture du projet

- `app.py` : Interface utilisateur principale (Streamlit).
- `document_processor.py` : Extraction de texte (pdfplumber, python-docx, odfpy, python-pptx) et d√©coupage intelligent (tiktoken).
- `llm_service.py` : Client API OpenAI, gestion des tokens et retry logic.
- `quiz_generator.py` : Logique de cr√©ation des QCM (prompts, parsing JSON).
- `exercise_generator.py` : Cr√©ation d'exercices et **V√©rification Agentique** (LangGraph + PythonREPLTool).
- `quiz_exporter.py` : Moteur de rendu HTML (Jinja2).
- `templates/quiz_template.html` : Template HTML/CSS/JS pour l'export des quizz.

## üì¶ D√©pendances principales

- `streamlit` : Interface Web.
- `langchain`, `langgraph`, `langchain-openai`, `langchain-experimental` : Orchestration LLM et Agents.
- `openai` : Client API standard.
- `pdfplumber`, `python-docx`, `odfpy`, `python-pptx` : Extraction multi-format.
- `tiktoken` : Tokenizer OpenAI rapide.
- `jinja2` : Templating HTML.

---

## ‚ö†Ô∏è Notes importantes

- **S√©curit√©** : L'agent de v√©rification des exercices ex√©cute du code Python g√©n√©r√© par le LLM **localement**. Bien que `PythonREPLTool` soit utilis√©, il n'y a pas de sandbox Docker par d√©faut. Utilisez ce logiciel dans un environnement de confiance ou configurez un environnement d'ex√©cution isol√© si n√©cessaire pour la production.
- **Mod√®les** : L'interface permet de choisir n'importe quel mod√®le disponible sur votre API. Test√© principalement avec `gtp-oss-120b`.
- **Chunking** : Deux modes sont disponibles : **Page par page** (recommand√© pour la pr√©cision des sources) et **Par blocs de tokens** (pour une analyse large, jusqu'√† 15 000 tokens).

## üìÑ Licence

Projet personnel / interne.
